{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c38fcd-8362-4921-89a0-e6254f63b0cd",
   "metadata": {},
   "source": [
    "<!-- # Table of Contents\n",
    "* [Introduction](#Introduction)\n",
    "* [Data Preparation and Cleaning](#Data-Preparation-and-Cleaning)\n",
    "  * [Importing the Data](#Importing-the-Data)\n",
    "  * [Duplicate and Missing Values](#Duplicate-and-Missing-Values)\n",
    "  * [Observations and Features](#Observations-and-Features)\n",
    "  * [Outliers](#Outliers)\n",
    "* [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "  * [Distribution of Features](#Distribution-of-Features)\n",
    "  * [Distribution of Features by Category](#Distribution-of-Features-by-Category)\n",
    "* [Correlation Analysis](#Correlation-Analysis)\n",
    "* [](#)\n",
    "* [Summary](#Summary) -->"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f52880fd",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Appendix 2\"\n",
    "author: \"Laima Lukoseviciute\"\n",
    "date: \\today\n",
    "jupyter: python3\n",
    "execute:\n",
    "  echo: false\n",
    "format:\n",
    "  pdf:\n",
    "    include-in-header:\n",
    "      - text: |\n",
    "          \\providecommand{\\MyProjectSubtitle}{}%\n",
    "          \\renewcommand{\\MyProjectSubtitle}{Preparing the Data Set}\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2323ca36-6293-4bba-a5eb-c14da0eb40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | include: false\n",
    "from IPython.display import display, Markdown\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import gc\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.asyncio import tqdm as atqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c8abb2c-7244-41b8-ba20-cdaedddecbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | include: false\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.data_utils import show_missing_values, calculate_precision\n",
    "from src.feature_utils import (\n",
    "    extract_tech_tools,\n",
    "    run_full_verification,\n",
    "    extract_job_titles,\n",
    "    checking_a_tool,\n",
    "    clean_us_states,\n",
    "    categorize_industry,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a26f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3a1ada",
   "metadata": {},
   "source": [
    "\\newpage\n",
    "# Introduction\n",
    "\n",
    "This report presents a data preparation for the EDA step for Coresignal jobs data. The primary goal of the further analyses will be to identify trends, relationships, and interesting angles within the Tech Stacks landscape of 2025.\n",
    "\n",
    "The initial raw data was gained from the Coresignal Multi-Source Jobs Dataset, which aggregates  listings from major global job boards. Since the Job listings for 2025 have more than 60 mln job postings I have decided to extract the job titles in the US, only where the job title contains selected keywords (plural of the words was also accepted):\n",
    "\n",
    "`developer` OR `analyst` OR `programmer` OR  `programming` OR `scientists` OR `data` OR `researcher` OR `engineer` OR `engineering`. \n",
    "\n",
    "The data was extracted using this SQL query that can be  seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e9c47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```sql\n",
       "\n",
       "            SELECT \n",
       "              title, description, company_name, company_industry, state, created_at,\n",
       "            FROM\n",
       "              `oxy-analytics.raw_external_cosi_core.multisource_job` \n",
       "            WHERE\n",
       "              created_at > \"2024-12-31\" AND\n",
       "              country = \"United States\" AND\n",
       "              REGEXP_CONTAINS(title, r\"(?i)\\b(developers?|analysts?|programmers?|programming|\n",
       "              scientists?|data|researchers?|engineers?|engineering)\\b\")\n",
       "            \n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | include: true\n",
    "sql_query = \"\"\"\n",
    "            SELECT \n",
    "              title, description, company_name, company_industry, state, created_at,\n",
    "            FROM\n",
    "              `oxy-analytics.raw_external_cosi_core.multisource_job` \n",
    "            WHERE\n",
    "              created_at > \"2024-12-31\" AND\n",
    "              country = \"United States\" AND\n",
    "              REGEXP_CONTAINS(title, r\"(?i)\\\\b(developers?|analysts?|programmers?|programming|\n",
    "              scientists?|data|researchers?|engineers?|engineering)\\\\b\")\n",
    "            \"\"\"\n",
    "\n",
    "display(Markdown(f\"```sql\\n{sql_query}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf0a137",
   "metadata": {},
   "source": [
    "The analyzed dataset has 6 primary features and over 2 062 382 observations, ranging from January 1, 2025 to December 31, 2025. For a detailed breakdown of the features, please refer to the @tbl-dictionary.\n",
    "\n",
    "| Variable Name    | Type     | Description |\n",
    "| -------------    | -------  | ----------- |\n",
    "|  title           | STRING   | The professional title of the job listing.|\n",
    "| description      | STRING   | The full text of the job post, used for keyword extraction.|\n",
    "| company_name     | STRING   | The name of the hiring organization. | \n",
    "| company_industry | STRING   | The sector the company operates in (e.g., Tech, Finance).|\n",
    "| state            | STRING   | The US state of the job location.|\n",
    "| created_at       | TIMESTAMP| The date when the job listing was added to the database.| \n",
    "\n",
    ": The description of variables for data. {#tbl-dictionary}\n",
    "\n",
    "A preview of the analysed dataset is presented below in @tbl-preview.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec8318c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_industry</th>\n",
       "      <th>state</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scientist (non-P...</td>\n",
       "      <td>Why Patients Nee...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California</td>\n",
       "      <td>2025-09-23 18:17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Scientist, C...</td>\n",
       "      <td>About Loyal Loya...</td>\n",
       "      <td>Loyal</td>\n",
       "      <td>Biotechnology Re...</td>\n",
       "      <td>California</td>\n",
       "      <td>2025-09-19 19:39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transit Coordina...</td>\n",
       "      <td>Posted: Oct 1, 2...</td>\n",
       "      <td>National Grants ...</td>\n",
       "      <td>Non-profit Organ...</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2025-09-29 09:04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Manager, ...</td>\n",
       "      <td>Description As t...</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Software Develop...</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>2025-09-10 20:07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Intelli...</td>\n",
       "      <td>Job Title: Busin...</td>\n",
       "      <td>IntelliSavvy</td>\n",
       "      <td>IT Services and ...</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2025-09-22 12:07...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title          description         company_name  \\\n",
       "0  Scientist (non-P...  Why Patients Nee...                  NaN   \n",
       "1  Sr. Scientist, C...  About Loyal Loya...                Loyal   \n",
       "2  Transit Coordina...  Posted: Oct 1, 2...  National Grants ...   \n",
       "3  Senior Manager, ...  Description As t...               Amazon   \n",
       "4  Business Intelli...  Job Title: Busin...         IntelliSavvy   \n",
       "\n",
       "      company_industry       state           created_at  \n",
       "0                  NaN  California  2025-09-23 18:17...  \n",
       "1  Biotechnology Re...  California  2025-09-19 19:39...  \n",
       "2  Non-profit Organ...       Texas  2025-09-29 09:04...  \n",
       "3  Software Develop...   Tennessee  2025-09-10 20:07...  \n",
       "4  IT Services and ...  Washington  2025-09-22 12:07...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-preview\n",
    "#| tbl-cap: \"Raw data pre-view first 5 rows. Note: if the table is not visible in pdf, please see html version of the report.\"\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/jobs_all_USA_2025_1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a2761c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Data Preparation\n",
    "\n",
    "The extracted data totals approximately 10 GB. To ensure the system processes this volume of information efficiently, I have partitioned the data into 11 separate files. After the programming language data is extracted, the \"description\" column will be removed. This adjustment allows the information from all files to be combined into a single dataset for the analysis and saved to the file \n",
    "`data/processed/jobs_proc_2025_no_desc.csv`. \n",
    "\n",
    "The function `extract_tech_tools` extracts these 23 tools: \"Excel\", \"Google_Sheets\", \"Fivetran\", \"Airbyte\", \"dbt\", \"Snowflake\", \"BigQuery\", \"Airflow\", \"Prefect\", \"Power BI\", \"Tableau\", \"Looker\", \"Git\", \"Docker\", \"Kubernetes\", \"Terraform\", \"AWS\", \"Azure\", \"GCP\", \"Databricks\", \"Kafka\", \"Spark\", \"Monte Carlo\". The detection of all the tools are handaled with regular expressions. To process the tools like \"Excel\", \"Airflow\", and \"Prefect\" I will be using LLM to interpret the meaning of these words in the description.\n",
    "\n",
    "\n",
    "Below you can see the list of all the tools which presence was evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9433f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code takes 30 minutes to run\n",
    "# os.makedirs(\"../data/processed/tools/\", exist_ok=True)\n",
    "\n",
    "# df_results_list = []\n",
    "\n",
    "# for i in range(1, 12):\n",
    "#     file_path = f\"../data/raw/jobs_all_USA_2025_{i}.csv\"\n",
    "#     print(f\"Processing: {file_path}\")\n",
    "#     df = pd.read_csv(file_path)\n",
    "#     df_processed = extract_tech_tools(df, \"description\")\n",
    "#     out_path = f\"../data/processed/tools/jobs_proc_all_USA_2025_{i}.csv\"\n",
    "\n",
    "#     df_processed.to_csv(out_path, index=False)\n",
    "#     df_no_desc = df_processed.drop(columns=[\"description\"])\n",
    "\n",
    "#     df_results_list.append(df_no_desc)\n",
    "#     del df\n",
    "#     del df_processed\n",
    "# df_results = pd.concat(df_results_list, ignore_index=True)\n",
    "# df_results.to_csv(\"../data/processed/tools/jobs_proc_2025_no_desc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f5b8415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Excel',\n",
       " 'Google_Sheets',\n",
       " 'Fivetran',\n",
       " 'Airbyte',\n",
       " 'dbt',\n",
       " 'Snowflake',\n",
       " 'BigQuery',\n",
       " 'Airflow',\n",
       " 'Prefect',\n",
       " 'Power_BI',\n",
       " 'Tableau',\n",
       " 'Looker',\n",
       " 'Git',\n",
       " 'Docker',\n",
       " 'Kubernetes',\n",
       " 'Terraform',\n",
       " 'AWS',\n",
       " 'Azure',\n",
       " 'GCP',\n",
       " 'Databricks',\n",
       " 'Kafka',\n",
       " 'Spark',\n",
       " 'Monte_Carlo']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/tools/jobs_proc_2025_no_desc.csv\")\n",
    "tech_tools = df.columns.tolist()[5:]\n",
    "tech_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a948015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: THIS CODE TAKES 26 HOURS TO RUN\n",
    "tools_to_verify = [\"Excel\", \"Airflow\", \"Prefect\"]\n",
    "# await run_full_verification([\"Excel\", \"Airflow\", \"Prefect\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e10291d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools_to_verify = [\"Excel\", \"Airflow\", \"Prefect\"]\n",
    "# final_df_list = []\n",
    "\n",
    "# for i in range(1, 12):\n",
    "#     shard_path = f\"../data/processed/tools/jobs_proc_all_USA_2025_{i}.csv\"\n",
    "#     df_shard = pd.read_csv(shard_path)\n",
    "#     for tool in tools_to_verify:\n",
    "#         ver_path = f\"../data/processed/tools/verification/verified_{tool}_shard_{i}.csv\"\n",
    "#         df_shard[f\"{tool}_verified\"] = 0\n",
    "#         df_tool_ver = pd.read_csv(ver_path)\n",
    "#         mask = df_shard[tool] == 1\n",
    "#         df_shard.loc[mask, f\"{tool}_verified\"] = df_tool_ver[f\"{tool}_verified\"].values\n",
    "#     df_clean = df_shard.drop(columns=[\"description\"])\n",
    "#     final_df_list.append(df_clean)\n",
    "\n",
    "# final_df = pd.concat(final_df_list, ignore_index=True)\n",
    "# final_df.to_csv(\"../data/processed/tools/final_verified_data_2025.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c708055",
   "metadata": {},
   "source": [
    "After verification process we have 3 additional columns in the data set: \"Excel_verified\", \"Airflow_verified\", and \"Prefect_verified\". Below @tbl-preview-tools you can see the preview of data with these new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4735cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2062297, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Excel</th>\n",
       "      <th>Excel_verified</th>\n",
       "      <th>Airflow_verified</th>\n",
       "      <th>Prefect_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scientist (non-P...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Scientist, C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transit Coordina...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Manager, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Intelli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title  Excel  Excel_verified  Airflow_verified  \\\n",
       "0  Scientist (non-P...      0               0                 0   \n",
       "1  Sr. Scientist, C...      0               0                 0   \n",
       "2  Transit Coordina...      0               0                 0   \n",
       "3  Senior Manager, ...      1               1                 0   \n",
       "4  Business Intelli...      0               0                 0   \n",
       "\n",
       "   Prefect_verified  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | label: tbl-preview-tools\n",
    "# | tbl-cap: \"Verified data pre-view first 5 rows. Note: if the table is not visible in pdf, please see html version of the report.\"\n",
    "\n",
    "df = pd.read_csv(f\"../data/processed/tools/final_verified_data_2025.csv\")\n",
    "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], format=\"mixed\", utc=True)\n",
    "df = df[df[\"created_at\"] >= \"2025-01-01\"]\n",
    "print(df.shape)\n",
    "df[[\"title\", \"Excel\", \"Excel_verified\", \"Airflow_verified\", \"Prefect_verified\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea207f",
   "metadata": {},
   "source": [
    "> NOTE:\n",
    ">\n",
    "> The `run_full_verification` function utilizes the Ollama Large Language Model (LLM) to identify the meaning of the words \"Excel\", \"Airflow\", and \"Prefect\". To ensure the most consistency of these results and minimize variability in model output, the temperature parameter is set to lower value.\n",
    "\n",
    "Below I will evaluate the error rate for the  tech tool detection precision. Which of them mean the tech tool and which of them do not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b795b34",
   "metadata": {},
   "source": [
    "Below at @tbl-precision you can see the preciton evaluation for tools \"Excel\", \"Airflow\", and \"Prefect\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b31cb0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tool</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excel</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airflow</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prefect</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tool  precision\n",
       "0    Excel       0.87\n",
       "1  Airflow       0.94\n",
       "2  Prefect       0.64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | label: tbl-precision\n",
    "# | tbl-cap: \"Precision evaluation for each tech tool\"\n",
    "\n",
    "df_precision = []\n",
    "for tool in tools_to_verify:\n",
    "    prec_tool = []\n",
    "    prec_tool.append(calculate_precision(df, tool, f\"{tool}_verified\"))\n",
    "    prec_tool = round(np.array(prec_tool).mean(), 2)\n",
    "    df_precision.append({\"tool\": tool, \"precision\": prec_tool})\n",
    "\n",
    "\n",
    "df_precision = pd.DataFrame(df_precision)\n",
    "df_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c9e02-3b63-4ba4-95e4-348b72c7eb33",
   "metadata": {},
   "source": [
    "## Observations and Features\n",
    "\n",
    "To make sure the function did what it was suppose to do let's do the exploration of the dataset's structure. I will examine the characteristics of each column to ensure data integrity and understand the available information.\n",
    "\n",
    "Below you can see the list of all the columns in the processed dataframe. All the programming languages were included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12684315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'company_name', 'company_industry', 'state', 'created_at',\n",
       "       'Excel', 'Google_Sheets', 'Fivetran', 'Airbyte', 'dbt', 'Snowflake',\n",
       "       'BigQuery', 'Airflow', 'Prefect', 'Power_BI', 'Tableau', 'Looker',\n",
       "       'Git', 'Docker', 'Kubernetes', 'Terraform', 'AWS', 'Azure', 'GCP',\n",
       "       'Databricks', 'Kafka', 'Spark', 'Monte_Carlo', 'Excel_verified',\n",
       "       'Airflow_verified', 'Prefect_verified'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f26ad9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"title\", \"company_name\", \"company_industry\", \"state\"]\n",
    "date_cols = [\"created_at\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ad3474",
   "metadata": {},
   "source": [
    "Below @tbl-description you can see the description of categorical data. We can see that there are 598373 unique title in the data and 107161 unique companies. Top industry is Software Development, and top state is California. At @tbl-description-date you can see that the data covers 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7ccfe88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_industry</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2062297</td>\n",
       "      <td>2039563</td>\n",
       "      <td>1782048</td>\n",
       "      <td>1459598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>598373</td>\n",
       "      <td>107161</td>\n",
       "      <td>427</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>Jobs via Dice</td>\n",
       "      <td>Software Develop...</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6863</td>\n",
       "      <td>68134</td>\n",
       "      <td>240228</td>\n",
       "      <td>215729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title   company_name     company_industry       state\n",
       "count             2062297        2039563              1782048     1459598\n",
       "unique             598373         107161                  427         138\n",
       "top     Financial Analyst  Jobs via Dice  Software Develop...  California\n",
       "freq                 6863          68134               240228      215729"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | label: tbl-description\n",
    "# | tbl-cap: \"Description of the categorical data\"\n",
    "\n",
    "df[cat_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8f403ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2062297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2025-06-22 23:52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2025-01-01 00:14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2025-03-25 02:28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2025-06-25 07:36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2025-09-12 19:41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025-12-19 09:18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_at\n",
       "count              2062297\n",
       "mean   2025-06-22 23:52...\n",
       "min    2025-01-01 00:14...\n",
       "25%    2025-03-25 02:28...\n",
       "50%    2025-06-25 07:36...\n",
       "75%    2025-09-12 19:41...\n",
       "max    2025-12-19 09:18..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | label: tbl-description-date\n",
    "# | tbl-cap: \"Description of the date data\"\n",
    "df[date_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630740d5",
   "metadata": {},
   "source": [
    "## Duplicate and Missing Values\n",
    "\n",
    "In this section I will analyse if the data set has any duplicated observations or missing values. From the outputs below (@tbl-missing-values) we can see that data have some missing values in column `state` 29% of values are missing, 14%  in column `company_industry`, and 1% in `company_name`. The full breakdown can be seen below in @tbl-missing-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a863f007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>no_values_missing</th>\n",
       "      <th>percentage_values_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>state</td>\n",
       "      <td>602699</td>\n",
       "      <td>29.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company_industry</td>\n",
       "      <td>280249</td>\n",
       "      <td>13.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>company_name</td>\n",
       "      <td>22734</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GCP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kubernetes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Terraform</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Azure</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Kafka</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Databricks</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Git</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Spark</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Monte_Carlo</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Excel_verified</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Airflow_verified</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Docker</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tableau</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Looker</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Power_BI</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Prefect</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Airflow</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BigQuery</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Snowflake</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dbt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Airbyte</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fivetran</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Google_Sheets</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Excel</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>created_at</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Prefect_verified</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         column_name  no_values_missing  percentage_values_missing\n",
       "3              state             602699                29.22      \n",
       "2   company_industry             280249                13.59      \n",
       "1       company_name              22734                 1.10      \n",
       "0              title                  0                 0.00      \n",
       "23               GCP                  0                 0.00      \n",
       "19        Kubernetes                  0                 0.00      \n",
       "20         Terraform                  0                 0.00      \n",
       "21               AWS                  0                 0.00      \n",
       "22             Azure                  0                 0.00      \n",
       "25             Kafka                  0                 0.00      \n",
       "24        Databricks                  0                 0.00      \n",
       "17               Git                  0                 0.00      \n",
       "26             Spark                  0                 0.00      \n",
       "27       Monte_Carlo                  0                 0.00      \n",
       "28    Excel_verified                  0                 0.00      \n",
       "29  Airflow_verified                  0                 0.00      \n",
       "18            Docker                  0                 0.00      \n",
       "15           Tableau                  0                 0.00      \n",
       "16            Looker                  0                 0.00      \n",
       "14          Power_BI                  0                 0.00      \n",
       "13           Prefect                  0                 0.00      \n",
       "12           Airflow                  0                 0.00      \n",
       "11          BigQuery                  0                 0.00      \n",
       "10         Snowflake                  0                 0.00      \n",
       "9                dbt                  0                 0.00      \n",
       "8            Airbyte                  0                 0.00      \n",
       "7           Fivetran                  0                 0.00      \n",
       "6      Google_Sheets                  0                 0.00      \n",
       "5              Excel                  0                 0.00      \n",
       "4         created_at                  0                 0.00      \n",
       "30  Prefect_verified                  0                 0.00      "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | label: tbl-missing-values\n",
    "# | tbl-cap: \"Missing values in the data set by column.\"\n",
    "\n",
    "show_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce9dce5",
   "metadata": {},
   "source": [
    "720756 were duplicated values. I will keep missing values, and will do the analyses with them in mind, and I will remove the duplicated values, since it is the same job posting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b062ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated values:  720756\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of duplicated values: \", df.duplicated().sum())\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a31a9f-5bb9-4081-82cb-08ee6d41d369",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "In this section let's look for some obvious outliers or other descrepencies in the data. The job `title` contains some obvious outliers, like resercher that is not related to data, but rather the academic enviroment, and egnineering manager mignt not need any knowlage of the programming languages, thus I will remove all the rows that have no mentions of any programming languages.\n",
    "I will also filter out the job\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "810bc941-0a4b-49ea-98bd-abc5d9a7bd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns after filtering jobs (rows) that have no mentions of tech tools:\n",
      "(596962, 31)\n"
     ]
    }
   ],
   "source": [
    "df[\"sum\"] = df[tech_tools].sum(axis=1)\n",
    "df = df[df[\"sum\"] > 0].copy()\n",
    "df = df.drop(columns=[\"sum\"])\n",
    "print(\n",
    "    \"Number of rows and columns after filtering jobs (rows) that have no mentions of tech tools:\"\n",
    ")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ffd789",
   "metadata": {},
   "source": [
    "Below you can see the list of all USA states that are in the data and needs to be cleaned and unified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e8737b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tennessee', 'Washington', 'California', 'District of Columbia',\n",
       "       'Massachusetts', 'Indiana', 'Florida', nan, 'Iowa', 'Texas',\n",
       "       'New Jersey', 'Illinois', 'Utah', 'New York', 'Maryland',\n",
       "       'Arizona', 'North Carolina', 'Virginia', 'Georgia', 'Ohio',\n",
       "       'Rhode Island', 'Connecticut', 'Oklahoma', 'Kansas', 'Mississippi',\n",
       "       'New Hampshire', 'North Dakota', 'Maine', 'Alabama', 'Wisconsin',\n",
       "       'Colorado', 'WI', 'Arkansas', 'Pennsylvania', 'South Carolina',\n",
       "       'Nebraska', 'Minnesota', 'Nevada', 'Missouri', 'Michigan',\n",
       "       'Hawaii', 'Kentucky', 'New Mexico', 'Wyoming', 'Oregon',\n",
       "       'United States', 'Delaware', 'Vermont', 'MN', 'Idaho', 'MA',\n",
       "       'Montana', 'South Dakota', 'Puerto Rico', 'Louisiana', 'MD',\n",
       "       'West Virginia', 'Alaska', 'TX', 'SC', 'Metropolitan Area', 'DC',\n",
       "       'GA', 'تكساس', 'San Juan', 'ND', 'US Virgin Islands',\n",
       "       'Gurabo Municipio', 'Carolina', 'Dededo Municipality',\n",
       "       'Eastern District', 'Barrigada Municipality', 'Sarasota Area',\n",
       "       'WA', 'Yigo Municipality', 'County', 'Guam', 'North', 'Young',\n",
       "       'Grants Pass Area', 'American Samoa', 'Virgin Islands',\n",
       "       'Guayanilla Municipio', 'Provincia de Las Palmas',\n",
       "       'Cayey Municipio', 'DE', 'indiana', 'Guaynabo', 'Chicago',\n",
       "       'U.S. Virgin Islands', 'मिज़ूरी', 'Washington D.C.', 'รัฐฟลอริดา',\n",
       "       'Floride', 'รัฐแคลิฟอร์เนีย', 'ميسوري', 'รัฐมิชิแกน',\n",
       "       'Doddridge County', 'Nowy Jork', 'Nueva York', 'Cidra Municipio',\n",
       "       'Municipality', 'FL', 'मेट्रोपॉलेटिन एरिया', 'ओहायो', 'states',\n",
       "       'オハイオ', 'Menomonie Area', 'Northern Mariana Islands'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"state\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a171f",
   "metadata": {},
   "source": [
    "These are states and US territories, which have left after the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62dd8418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique states after cleaning:  55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California',\n",
       "       'Colorado', 'Connecticut', 'Delaware', 'District of Columbia',\n",
       "       'Florida', 'Georgia', 'Guam', 'Hawaii', 'Idaho', 'Illinois',\n",
       "       'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine',\n",
       "       'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
       "       'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
       "       'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
       "       'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
       "       'Pennsylvania', 'Puerto Rico', 'Rhode Island', 'South Carolina',\n",
       "       'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont',\n",
       "       'Virgin Islands', 'Virginia', 'Washington', 'West Virginia',\n",
       "       'Wisconsin', 'Wyoming'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"state\"] = clean_us_states(df[\"state\"])\n",
    "print(\"Number of unique states after cleaning: \", len(df[\"state\"].unique()))\n",
    "np.sort(df[\"state\"].dropna().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff9fa7e",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "To improve the clarity of the recruitment landscape, I am standardizing the industry classifications within the dataset. Currently, the data includes 427 unique industries, many of which overlap or share similar characteristics. This level of granularity can make it difficult to identify broader market trends.\n",
    "\n",
    "I have grouped these industries into 11 primary categories to make the analysis more accessible and highlight high-level patterns. The distribution of job postings across these groups is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02d02f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broad_industry_group</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tech, Data &amp; Telecom</th>\n",
       "      <td>226571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Professional, Legal &amp; Business Services</th>\n",
       "      <td>87252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miscellaneous</th>\n",
       "      <td>76292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finance, Insurance &amp; Real Estate</th>\n",
       "      <td>61138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manufacturing, Industrial &amp; Defense</th>\n",
       "      <td>55533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthcare, Pharma &amp; Wellness</th>\n",
       "      <td>23832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistics, Travel &amp; Construction</th>\n",
       "      <td>19385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education, Government &amp; Non-profit</th>\n",
       "      <td>15065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer, Retail &amp; Agriculture</th>\n",
       "      <td>12883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Energy, Utilities &amp; Environment</th>\n",
       "      <td>12372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media, Entertainment &amp; Arts</th>\n",
       "      <td>6639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count\n",
       "broad_industry_group        \n",
       "Tech, Data & Telecom  226571\n",
       "Professional, Leg...   87252\n",
       "Miscellaneous          76292\n",
       "Finance, Insuranc...   61138\n",
       "Manufacturing, In...   55533\n",
       "Healthcare, Pharm...   23832\n",
       "Logistics, Travel...   19385\n",
       "Education, Govern...   15065\n",
       "Consumer, Retail ...   12883\n",
       "Energy, Utilities...   12372\n",
       "Media, Entertainm...    6639"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"broad_industry_group\"] = df[\"company_industry\"].apply(categorize_industry)\n",
    "\n",
    "pd.DataFrame(df[\"broad_industry_group\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b71626",
   "metadata": {},
   "source": [
    "To provide a more structured view of the recruitment landscape, I am standardizing the job titles within the dataset. Currently, the data contains approximately 600 000 unique job titles, which is a level of detail that can obscure broader market trends.\n",
    "\n",
    "By grouping these titles into five primary categories, the analysis becomes more accessible for identifying high-level patterns. These categories include:\n",
    "\n",
    "- Manager: Roles focused on leadership and project oversight.\n",
    "\n",
    "- Engineer: Positions centered on building and maintaining technical systems.\n",
    "\n",
    "- Analyst: Roles dedicated to interpreting data and providing insights.\n",
    "\n",
    "- Scientist: Research-oriented positions, including Data Scientists and Researchers.\n",
    "\n",
    "- Developer: Traditional software creation and programming roles.\n",
    "\n",
    "This categorization simplifies the comparison of programming language requirements across different professional functions. The final dataframe can be found in file `data/processed/tools/jobs_filtered_2025_no_desc.csv`. The @tbl-final-df shows the preview to the final data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2944448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(596962, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>broad_industry_group</th>\n",
       "      <th>analyst</th>\n",
       "      <th>engineer</th>\n",
       "      <th>Excel</th>\n",
       "      <th>Airflow</th>\n",
       "      <th>Excel_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Manager, ...</td>\n",
       "      <td>Tech, Data &amp; Tel...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Intelli...</td>\n",
       "      <td>Tech, Data &amp; Tel...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HAZARDOUS SUBSTA...</td>\n",
       "      <td>Energy, Utilitie...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PMS 378 Senior T...</td>\n",
       "      <td>Tech, Data &amp; Tel...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>COMPENSATION ANA...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title broad_industry_group  analyst  engineer  Excel  \\\n",
       "3   Senior Manager, ...  Tech, Data & Tel...        0         1      1   \n",
       "4   Business Intelli...  Tech, Data & Tel...        0         1      0   \n",
       "5   HAZARDOUS SUBSTA...  Energy, Utilitie...        0         1      1   \n",
       "8   PMS 378 Senior T...  Tech, Data & Tel...        1         0      1   \n",
       "11  COMPENSATION ANA...        Miscellaneous        1         0      1   \n",
       "\n",
       "    Airflow  Excel_verified  \n",
       "3         0               1  \n",
       "4         0               0  \n",
       "5         0               1  \n",
       "8         0               1  \n",
       "11        0               1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | label: tbl-final-df\n",
    "# | tbl-cap: \"Final data set pre-view first 5 rows and 7 columns. Note: if the table is not visible in pdf, please see html version of the report.\"\n",
    "\n",
    "df_filtered = extract_job_titles(df, title_col=\"title\")\n",
    "\n",
    "df_filtered.to_csv(\n",
    "    \"../data/processed/tools/jobs_proc_filtered_2025_no_desc.csv\", index=False\n",
    ")\n",
    "print(df_filtered.shape)\n",
    "df_filtered[\n",
    "    [\n",
    "        \"title\",\n",
    "        \"broad_industry_group\",\n",
    "        \"analyst\",\n",
    "        \"engineer\",\n",
    "        \"Excel\",\n",
    "        \"Airflow\",\n",
    "        \"Excel_verified\",\n",
    "    ]\n",
    "].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b682ea-a535-43f9-912c-b3770c8a9141",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This stage of the project focused on transforming around 10 GB of raw job posting data from the Coresignal Multi-Source Jobs Dataset into a structured, analysis-ready format. To ensure the data remained manageable on local hardware while maintaining depth, the following steps were completed:\n",
    "\n",
    "- Targeted Extraction: I have narrowed the scope to over 2 000 000 observations from 2025 specifically within the United States, filtering for key technical roles such as developers, analysts, and engineers.\n",
    "\n",
    "- Data Integrity: The dataset was refined by removing more than 720 000 duplicate entries and filtering out job titles that lacked any tech tools mentions (e.g., academic researchers or pure management roles).\n",
    "\n",
    "- Technical Standardization: I have identified mentions of 23 tech tools. Ambiguous terms like \"Excel\" were processed using a local Large Language Model (Ollama).\n",
    "\n",
    "- Categorization: To understand market trends, I have engineered five high-level job categories: Manager, Engineer, Analyst, Scientist, and Developer.\n",
    "\n",
    "The resulting processed dataset contains 602 359 high-quality job postings, significantly reduced from the initial data, allowing for efficient and high-impact EDA.\n",
    "\n",
    "# Suggestions for Further Improvements\n",
    "\n",
    "The error rate calculations for the LLM used for the interpretation tech tools could be done. I think this will be marginal improvement and will not change the results that much, but just for the sake of being precice and redusing the error this should be done. \n",
    "\n",
    "There could be some other jobs that require these tools and are in the tech position but the Coresignal data fields were lacking this information in the job title or description, because the fields were not present in the data of mixed.\n",
    "\n",
    "There are also other tools that could be added specifically talking about the developers, but the additional analyses, should be conducted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
