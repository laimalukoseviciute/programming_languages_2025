{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c38fcd-8362-4921-89a0-e6254f63b0cd",
   "metadata": {},
   "source": [
    "<!-- # Table of Contents\n",
    "* [Introduction](#Introduction)\n",
    "* [Data Preparation and Cleaning](#Data-Preparation-and-Cleaning)\n",
    "  * [Importing the Data](#Importing-the-Data)\n",
    "  * [Duplicate and Missing Values](#Duplicate-and-Missing-Values)\n",
    "  * [Observations and Features](#Observations-and-Features)\n",
    "  * [Outliers](#Outliers)\n",
    "* [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "  * [Distribution of Features](#Distribution-of-Features)\n",
    "  * [Distribution of Features by Category](#Distribution-of-Features-by-Category)\n",
    "* [Correlation Analysis](#Correlation-Analysis)\n",
    "* [](#)\n",
    "* [Summary](#Summary) -->"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f52880fd",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Project Title\"\n",
    "author: \"Laima Lukoseviciute\"\n",
    "date: \\today\n",
    "jupyter: python3\n",
    "execute:\n",
    "  echo: false\n",
    "format:\n",
    "  pdf:\n",
    "    include-in-header:\n",
    "      - text: |\n",
    "          \\providecommand{\\MyProjectSubtitle}{}%\n",
    "          \\renewcommand{\\MyProjectSubtitle}{Subtitle text}\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3a1ada",
   "metadata": {},
   "source": [
    "\\newpage\n",
    "# Introduction\n",
    "\n",
    "This report presents an exploratory data analysis of [...] data. The primary goal is [to identify trends, relationships, and interesting angles] within the data that could serve as a foundation for media pitches or blog content, targeting both C-level executives and technical audiences in the IT and data industries. The analysis focuses on understanding [...].\n",
    "\n",
    "The initial raw data was gained from [...]. The analysed data set has [...] features and [...] observations, ranging from [...] to [...]. For a detailed breakdown of the features, please refer to the @tbl-dictionary. \n",
    "\n",
    "| Variable Name | Type    | Description |\n",
    "| ------------- | ------- | ----------- |\n",
    "| Var1 | STRING | This is var 1. |\n",
    "| Var2 | INTEGER | This is var 2. |\n",
    "| Date | TIMESTAMP | The date of the .|\n",
    "\n",
    "\n",
    ": The description of variables for data. {#tbl-dictionary}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a2761c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Data Preparation and Cleaning\n",
    "\n",
    "In this section, I examine the dataset to ensure its quality and reliability before analysis. I check for missing or duplicate values, identify potential outliers or typos, and address any inconsistencies. Additionally, I create new derived features where needed to better capture important patterns and support the subsequent analysis.\n",
    "\n",
    "A preview of the analysed dataset is presented below in @tbl-preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323ca36-6293-4bba-a5eb-c14da0eb40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8abb2c-7244-41b8-ba20-cdaedddecbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.viz_utils import (\n",
    "    function_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a99271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "# Setting plotting style\n",
    "plt.style.use(\"fast\")\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"Avenir\",       \n",
    "    \"text.color\": \"#130f35\",\n",
    "    \"axes.labelcolor\": \"#130f35\",\n",
    "    \"xtick.color\": \"#130f35\",\n",
    "    \"ytick.color\": \"#130f35\",\n",
    "    \"figure.facecolor\": \"none\",\n",
    "    \"axes.facecolor\": \"none\",\n",
    "    \"savefig.transparent\": True,\n",
    "})\n",
    "\n",
    "oxylab_cmap = LinearSegmentedColormap.from_list(\n",
    "    \"custom_cmap\", [\"#130f35\", \"#52A8F8\", \"#23E6A8\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5074b299-4023-4624-9854-a429e586dfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: tbl-preview\n",
    "#| tbl-cap: \"Raw data pre-view first 5 rows\"\n",
    "df = pd.read_csv(\"../data/file_name.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f9712-deea-4528-ab3d-256111055af7",
   "metadata": {},
   "source": [
    "## Duplicate and Missing Values\n",
    "\n",
    "In this section I will analyse if the data set has any duplicated observations or missing values. From the outputs below we can see that data have [...] missing values and [...] duplicated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac7f1e-91a6-444d-955f-b00a89953402",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of missing values:\")\n",
    "df.isna().sum()\n",
    "# df.dropna(subset=[\"var1\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229cb26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of duplicated values:\")\n",
    "df.duplicated().sum()\n",
    "# df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c9e02-3b63-4ba4-95e4-348b72c7eb33",
   "metadata": {},
   "source": [
    "## Observations and Features\n",
    "\n",
    "This section begins the detailed exploration of the dataset's structure. I will examine the characteristics of each column to ensure data integrity and understand the available information.\n",
    "\n",
    "Specifically, for quantitative features (like [...]), I'll inspect the distribution and range of values. For categorical features (like [...]), we'll identify the distinct categories present and count the number of unique observations in each. This step confirms the data types and prepares us for subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190d812-137e-431e-a1ba-4c3cedf85326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"var1\"].describe()\n",
    "#df[\"var2\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a31a9f-5bb9-4081-82cb-08ee6d41d369",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "In this section let's look for typos some obvious outliers or other descrepencies in the data. The [...] column contains [...] values, thus [...]. Additionally, since there are [...], I will explore ways to consolidate or improve this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810bc941-0a4b-49ea-98bd-abc5d9a7bd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bd4efda",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "To gain deeper insights into the data, I'll create new features. The resulting features will facilitate achieving the core goals of this analysis by [...]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7797f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c445811-574a-49c1-a867-6e50bcb83f85",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "This section focuses on performing a detailed Exploratory Data Analysis. The goal is to visually and statistically summarize the main characteristics of the dataset, identifying initial patterns, and forming hypotheses that will guide the subsequent [...] phases. I'll start by [...].\n",
    "\n",
    "## Distribution of Features\n",
    "\n",
    "Understanding the distribution of each feature is the foundation of any analysis. We'll use graphical representations like histograms and density plots to assess t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc18cf-a6d6-4aca-90e2-d60099df0b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0ff5ee1",
   "metadata": {},
   "source": [
    "From this we can see that [...]\n",
    "\n",
    "> GUIDELINES:\n",
    "> - Spot the trend\n",
    "> - Ask Why this happend?\n",
    "> - Try to explore the dimensions to fige out the reason?\n",
    "> - Identify patters and sumaries them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eecf07-0fb6-4fb0-8650-561c90092d16",
   "metadata": {},
   "source": [
    "## Distribution of Features by Category\n",
    "\n",
    "Understanding the distribution of how each feature is distributed in each category is important. We'll use graphical representations like histograms and density plots to assess t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae5edf0-4ba7-406b-aa22-3e1614bb1f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15ca80-e9ce-464a-b7ba-2ccf09978875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "907c81ea-253b-4963-b70a-7844b66d53c9",
   "metadata": {},
   "source": [
    "From this we can see that [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b682ea-a535-43f9-912c-b3770c8a9141",
   "metadata": {},
   "source": [
    "# Key Insights\n",
    "\n",
    "This section synthesizes the most significant findings and patterns identified during the Exploratory Data Analysis (EDA) and subsequent modeling. We translate the statistical and visual evidence into clear, actionable insights regarding network performance, proxy efficiency, and data retrieval characteristics. These insights serve as the foundation for media narratives and strategic decision-making.\n",
    "\n",
    "# Summary\n",
    "\n",
    "This summary provides a concise overview of the entire project, recapping the data source, the scope of the analysis, and the primary conclusions reached regarding the performance and characteristics of the proxy network. It serves as a stand-alone digest for executive-level audiences and colleagues, highlighting the value and business implications of the findings.\n",
    "\n",
    "# Suggestions for Further Improvements\n",
    "\n",
    "Based on the patterns observed and the performance metrics analyzed, this section outlines potential next steps for refining the data collection process, enhancing the proxy network infrastructure, or expanding the scope of the analysis. These suggestions are intended to maximize efficiency and further optimize the data scraping solutions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
